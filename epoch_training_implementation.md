# TensorFlow/PyTorch Epochè½®æ¬¡è®­ç»ƒå®ç°è¯´æ˜

## ğŸ“‹ å½“å‰ç³»ç»ŸçŠ¶æ€åˆ†æ

### âœ… å·²æ”¯æŒçš„åŠŸèƒ½
1. **åŸºç¡€æ·±åº¦å­¦ä¹ è®­ç»ƒå™¨**: `DeepLearningTrainer`ç±»å·²å­˜åœ¨
2. **è®­ç»ƒé…ç½®æ¨¡å‹**: `TrainingConfig`æ”¯æŒepochså‚æ•°
3. **è®­ç»ƒå†å²è®°å½•**: `TrainingHistoryLogger`ç±»å·²å®ç°
4. **æ¨¡å‹ä¿å­˜**: æ”¯æŒå¤šç§æ ¼å¼ä¿å­˜

### âŒ ç¼ºå¤±çš„åŠŸèƒ½
1. **å®æ—¶epochè¿›åº¦ç›‘æ§**: æ— æ³•å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦
2. **epochçº§åˆ«çš„æŒ‡æ ‡è®°å½•**: ç¼ºå°‘æ¯ä¸ªepochçš„è¯¦ç»†æŒ‡æ ‡
3. **è®­ç»ƒä¸­æ–­å’Œæ¢å¤**: ä¸æ”¯æŒè®­ç»ƒä¸­æ–­åæ¢å¤
4. **æ—©åœæœºåˆ¶**: ç¼ºå°‘è‡ªåŠ¨æ—©åœåŠŸèƒ½
5. **å­¦ä¹ ç‡è°ƒåº¦**: ç¼ºå°‘åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
6. **å¤šGPUæ”¯æŒ**: ç¼ºå°‘åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

## ğŸ¯ å®ç°ç›®æ ‡

### 1. **å®Œæ•´çš„Epochè®­ç»ƒæµç¨‹**
```python
# ç›®æ ‡å®ç°
class EpochTrainingManager:
    def train_with_epochs(self, model, data, config):
        for epoch in range(config.epochs):
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self.train_epoch(model, data)
            
            # éªŒè¯
            val_metrics = self.validate_epoch(model, val_data)
            
            # è®°å½•æŒ‡æ ‡
            self.log_epoch_metrics(epoch, train_metrics, val_metrics)
            
            # æ£€æŸ¥æ—©åœ
            if self.should_early_stop(val_metrics):
                break
```

### 2. **å®æ—¶è¿›åº¦ç›‘æ§**
```python
# å®æ—¶è¿›åº¦å›è°ƒ
def epoch_callback(epoch, logs):
    # å‘é€è¿›åº¦åˆ°å‰ç«¯
    websocket.send({
        'type': 'epoch_progress',
        'epoch': epoch,
        'metrics': logs
    })
```

### 3. **è®­ç»ƒçŠ¶æ€ç®¡ç†**
```python
# è®­ç»ƒçŠ¶æ€
class TrainingState:
    PENDING = "pending"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
```

## ğŸ”§ å®ç°æ–¹æ¡ˆ

### 1. **å¢å¼ºçš„æ·±åº¦å­¦ä¹ è®­ç»ƒå™¨**

#### **A. æ–°å¢Epochè®­ç»ƒå™¨ç±»**
```python
class EpochDeepLearningTrainer(DeepLearningTrainer):
    """æ”¯æŒå®Œæ•´epochè®­ç»ƒçš„æ·±åº¦å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(self):
        super().__init__()
        self.epoch_history = []
        self.current_epoch = 0
        self.best_metrics = {}
        self.early_stopping_patience = 10
        self.learning_rate_scheduler = None
```

#### **B. Epochè®­ç»ƒæ–¹æ³•**
```python
async def train_with_epochs(self, config: TrainingConfig, data: Dict[str, Any]) -> TrainingResult:
    """æ‰§è¡Œå®Œæ•´çš„epochè®­ç»ƒ"""
    
    # åˆå§‹åŒ–è®­ç»ƒ
    self._initialize_training(config, data)
    
    # å¼€å§‹epochè®­ç»ƒ
    for epoch in range(config.epochs):
        try:
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = await self._train_single_epoch(epoch, config)
            
            # éªŒè¯
            val_metrics = await self._validate_epoch(epoch, config)
            
            # è®°å½•æŒ‡æ ‡
            self._log_epoch_metrics(epoch, train_metrics, val_metrics)
            
            # æ›´æ–°å­¦ä¹ ç‡
            self._update_learning_rate(epoch, val_metrics)
            
            # æ£€æŸ¥æ—©åœ
            if self._should_early_stop(val_metrics):
                logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬{epoch}è½®åœæ­¢è®­ç»ƒ")
                break
                
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if self._is_best_model(val_metrics):
                self._save_best_model(config)
                
        except Exception as e:
            logger.error(f"ç¬¬{epoch}è½®è®­ç»ƒå¤±è´¥: {str(e)}")
            raise
```

### 2. **å®æ—¶ç›‘æ§ç³»ç»Ÿ**

#### **A. WebSocketè¿›åº¦æ¨é€**
```python
class TrainingProgressManager:
    """è®­ç»ƒè¿›åº¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.websocket_connections = {}
        self.progress_callbacks = {}
    
    def register_progress_callback(self, task_id: str, callback):
        """æ³¨å†Œè¿›åº¦å›è°ƒ"""
        self.progress_callbacks[task_id] = callback
    
    def broadcast_epoch_progress(self, task_id: str, epoch: int, metrics: Dict):
        """å¹¿æ’­epochè¿›åº¦"""
        progress_data = {
            'task_id': task_id,
            'epoch': epoch,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        # å‘é€åˆ°WebSocket
        if task_id in self.websocket_connections:
            for connection in self.websocket_connections[task_id]:
                connection.send_json(progress_data)
```

#### **B. è®­ç»ƒçŠ¶æ€API**
```python
@router.get("/training/progress/{task_id}")
async def get_training_progress(task_id: str):
    """è·å–è®­ç»ƒè¿›åº¦"""
    progress_manager = TrainingProgressManager()
    return await progress_manager.get_progress(task_id)

@router.post("/training/pause/{task_id}")
async def pause_training(task_id: str):
    """æš‚åœè®­ç»ƒ"""
    return await training_manager.pause_training(task_id)

@router.post("/training/resume/{task_id}")
async def resume_training(task_id: str):
    """æ¢å¤è®­ç»ƒ"""
    return await training_manager.resume_training(task_id)
```

### 3. **æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦**

#### **A. æ—©åœæœºåˆ¶**
```python
class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.best_metric = None
        self.counter = 0
    
    def should_stop(self, current_metric: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ—©åœ"""
        if self.best_metric is None:
            self.best_metric = current_metric
            return False
        
        if current_metric > self.best_metric + self.min_delta:
            self.best_metric = current_metric
            self.counter = 0
        else:
            self.counter += 1
            
        return self.counter >= self.patience
```

#### **B. å­¦ä¹ ç‡è°ƒåº¦å™¨**
```python
class LearningRateScheduler:
    """å­¦ä¹ ç‡è°ƒåº¦å™¨"""
    
    def __init__(self, initial_lr: float, scheduler_type: str = 'step'):
        self.initial_lr = initial_lr
        self.current_lr = initial_lr
        self.scheduler_type = scheduler_type
    
    def step(self, epoch: int, metrics: Dict[str, float]):
        """æ›´æ–°å­¦ä¹ ç‡"""
        if self.scheduler_type == 'step':
            if epoch % 30 == 0:
                self.current_lr *= 0.1
        elif self.scheduler_type == 'plateau':
            if 'val_loss' in metrics:
                if metrics['val_loss'] > self.best_val_loss:
                    self.current_lr *= 0.5
                    self.best_val_loss = metrics['val_loss']
```

### 4. **å¤šGPUæ”¯æŒ**

#### **A. TensorFlowå¤šGPU**
```python
def create_multi_gpu_model(model_type: str, params: Dict, input_dim: int):
    """åˆ›å»ºå¤šGPUæ¨¡å‹"""
    try:
        import tensorflow as tf
        
        # æ£€æŸ¥GPUæ•°é‡
        gpus = tf.config.list_physical_devices('GPU')
        if len(gpus) > 1:
            # ä½¿ç”¨MirroredStrategy
            strategy = tf.distribute.MirroredStrategy()
            with strategy.scope():
                return create_model(model_type, params, input_dim)
        else:
            return create_model(model_type, params, input_dim)
    except ImportError:
        logger.warning("TensorFlowæœªå®‰è£…")
        return None
```

#### **B. PyTorchå¤šGPU**
```python
def create_multi_gpu_model_pytorch(model_type: str, params: Dict, input_dim: int):
    """åˆ›å»ºPyTorchå¤šGPUæ¨¡å‹"""
    try:
        import torch
        
        model = create_pytorch_model(model_type, params, input_dim)
        
        # æ£€æŸ¥GPUæ•°é‡
        if torch.cuda.device_count() > 1:
            model = torch.nn.DataParallel(model)
            
        return model
    except ImportError:
        logger.warning("PyTorchæœªå®‰è£…")
        return None
```

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### 1. **Epochçº§åˆ«æŒ‡æ ‡**
```python
epoch_metrics = {
    'epoch': 1,
    'train_loss': 0.234,
    'train_accuracy': 0.856,
    'val_loss': 0.198,
    'val_accuracy': 0.872,
    'learning_rate': 0.001,
    'time_per_epoch': 45.2,
    'memory_usage': 2048,
    'gpu_utilization': 85.6
}
```

### 2. **è®­ç»ƒå†å²è®°å½•**
```python
training_history = {
    'epochs': [1, 2, 3, 4, 5],
    'train_loss': [0.234, 0.198, 0.167, 0.145, 0.123],
    'val_loss': [0.198, 0.167, 0.145, 0.123, 0.112],
    'train_accuracy': [0.856, 0.872, 0.889, 0.901, 0.912],
    'val_accuracy': [0.872, 0.889, 0.901, 0.912, 0.923]
}
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. **å¯åŠ¨Epochè®­ç»ƒ**
```python
# é…ç½®è®­ç»ƒå‚æ•°
config = TrainingConfig(
    name="æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
    algorithm_type=AlgorithmType.DEEP_LEARNING,
    epochs=100,
    batch_size=32,
    learning_rate=0.001,
    train_data_path="/data/train.csv",
    feature_columns=["feature1", "feature2", "feature3"],
    target_column="target",
    algorithm_params={
        'model_type': 'mlp',
        'hidden_units': [128, 64, 32],
        'dropout_rate': 0.2,
        'early_stopping_patience': 10,
        'learning_rate_scheduler': 'step'
    },
    output_path="/models/deep_learning_model"
)

# å¯åŠ¨è®­ç»ƒ
trainer = EpochDeepLearningTrainer()
result = await trainer.train_with_epochs(config, data)
```

### 2. **ç›‘æ§è®­ç»ƒè¿›åº¦**
```python
# æ³¨å†Œè¿›åº¦å›è°ƒ
def progress_callback(epoch, metrics):
    print(f"Epoch {epoch}: Loss={metrics['train_loss']:.4f}, "
          f"Accuracy={metrics['train_accuracy']:.4f}")

trainer.register_progress_callback(progress_callback)
```

### 3. **APIæ¥å£è°ƒç”¨**
```http
POST /api/v1/algorithm/epoch-train
Content-Type: application/json

{
  "name": "æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
  "algorithm_type": "deep_learning",
  "epochs": 100,
  "batch_size": 32,
  "learning_rate": 0.001,
  "train_data_path": "/data/train.csv",
  "feature_columns": ["feature1", "feature2", "feature3"],
  "target_column": "target",
  "algorithm_params": {
    "model_type": "mlp",
    "hidden_units": [128, 64, 32],
    "dropout_rate": 0.2,
    "early_stopping_patience": 10,
    "learning_rate_scheduler": "step"
  },
  "output_path": "/models/deep_learning_model"
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. **å†…å­˜ä¼˜åŒ–**
- ä½¿ç”¨æ•°æ®ç”Ÿæˆå™¨å‡å°‘å†…å­˜å ç”¨
- å®ç°æ¢¯åº¦ç´¯ç§¯æ”¯æŒå¤§æ‰¹æ¬¡è®­ç»ƒ
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒå‡å°‘æ˜¾å­˜ä½¿ç”¨

### 2. **è®¡ç®—ä¼˜åŒ–**
- ä½¿ç”¨TensorRTè¿›è¡Œæ¨¡å‹ä¼˜åŒ–
- å®ç°æ¨¡å‹é‡åŒ–å‡å°‘è®¡ç®—é‡
- ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿ

### 3. **å­˜å‚¨ä¼˜åŒ–**
- å®ç°æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ¢å¤
- ä½¿ç”¨å¢é‡ä¿å­˜å‡å°‘å­˜å‚¨ç©ºé—´
- å®ç°æ¨¡å‹å‹ç¼©å‡å°‘æ–‡ä»¶å¤§å°

## ğŸ”„ åç»­æ‰©å±•è®¡åˆ’

### 1. **é«˜çº§åŠŸèƒ½**
- è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–
- æ¨¡å‹æ¶æ„æœç´¢
- è”é‚¦å­¦ä¹ æ”¯æŒ

### 2. **ç›‘æ§å¢å¼º**
- å®æ—¶èµ„æºä½¿ç”¨ç›‘æ§
- è®­ç»ƒå¯è§†åŒ–ç•Œé¢
- æ€§èƒ½ç“¶é¢ˆåˆ†æ

### 3. **éƒ¨ç½²ä¼˜åŒ–**
- æ¨¡å‹æœåŠ¡åŒ–éƒ¨ç½²
- åœ¨çº¿å­¦ä¹ æ”¯æŒ
- A/Bæµ‹è¯•æ¡†æ¶

è¿™ä¸ªå®ç°æ–¹æ¡ˆå°†ä¸ºç³»ç»Ÿæä¾›å®Œæ•´çš„TensorFlow/PyTorch epochè½®æ¬¡è®­ç»ƒæ”¯æŒï¼ŒåŒ…æ‹¬å®æ—¶ç›‘æ§ã€æ—©åœæœºåˆ¶ã€å­¦ä¹ ç‡è°ƒåº¦ç­‰é«˜çº§åŠŸèƒ½ã€‚ 