#!/usr/bin/env python3
"""
GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•è„šæœ¬
éªŒè¯GPUèµ„æºåˆ†é…ã€ç›‘æ§å’Œè®­ç»ƒåŠŸèƒ½
"""
import asyncio
import logging
import sys
import os
from typing import Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

from backend.algorithm_engine.gpu_resource_integration import (
    get_gpu_resource_manager,
    get_tensorflow_gpu_integration,
    get_pytorch_gpu_integration,
    TrainingGPUConfig
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class GPUResourceIntegrationTest:
    """GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•"""
    
    def __init__(self):
        self.gpu_manager = get_gpu_resource_manager()
        self.tensorflow_gpu = get_tensorflow_gpu_integration()
        self.pytorch_gpu = get_pytorch_gpu_integration()
    
    def test_gpu_manager_initialization(self):
        """æµ‹è¯•GPUç®¡ç†å™¨åˆå§‹åŒ–"""
        logger.info("=== æµ‹è¯•GPUç®¡ç†å™¨åˆå§‹åŒ– ===")
        
        try:
            if self.gpu_manager.initialized:
                logger.info("âœ… GPUèµ„æºç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                return True
            else:
                logger.warning("âš ï¸ GPUèµ„æºç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                return False
        except Exception as e:
            logger.error(f"âŒ GPUç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def test_gpu_resource_status(self):
        """æµ‹è¯•GPUèµ„æºçŠ¶æ€æŸ¥è¯¢"""
        logger.info("=== æµ‹è¯•GPUèµ„æºçŠ¶æ€æŸ¥è¯¢ ===")
        
        try:
            status = self.gpu_manager.get_gpu_monitoring_data()
            logger.info(f"GPUç›‘æ§æ•°æ®: {status}")
            
            if status.get('error'):
                logger.warning(f"âš ï¸ GPUç›‘æ§æ•°æ®è·å–å¤±è´¥: {status['error']}")
                return False
            else:
                logger.info("âœ… GPUèµ„æºçŠ¶æ€æŸ¥è¯¢æˆåŠŸ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ GPUèµ„æºçŠ¶æ€æŸ¥è¯¢å¤±è´¥: {e}")
            return False
    
    def test_gpu_node_discovery(self):
        """æµ‹è¯•GPUèŠ‚ç‚¹å‘ç°"""
        logger.info("=== æµ‹è¯•GPUèŠ‚ç‚¹å‘ç° ===")
        
        try:
            # æµ‹è¯•ä¸åŒGPUç±»å‹çš„èŠ‚ç‚¹å‘ç°
            gpu_types = ['V100', 'A100', 'T4', None]
            
            for gpu_type in gpu_types:
                nodes = self.gpu_manager.get_available_gpu_nodes(
                    gpu_type=gpu_type,
                    min_memory_gb=16.0
                )
                
                logger.info(f"GPUç±»å‹ {gpu_type}: å‘ç° {len(nodes)} ä¸ªå¯ç”¨èŠ‚ç‚¹")
                
                for node in nodes:
                    logger.info(f"  - èŠ‚ç‚¹: {node.node_name}, "
                              f"GPUç±»å‹: {node.gpu_type}, "
                              f"å¯ç”¨GPU: {node.available_gpus}, "
                              f"æ˜¾å­˜: {node.memory_per_gpu}GB")
            
            logger.info("âœ… GPUèŠ‚ç‚¹å‘ç°æµ‹è¯•æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GPUèŠ‚ç‚¹å‘ç°æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_gpu_resource_validation(self):
        """æµ‹è¯•GPUèµ„æºéœ€æ±‚éªŒè¯"""
        logger.info("=== æµ‹è¯•GPUèµ„æºéœ€æ±‚éªŒè¯ ===")
        
        try:
            # æµ‹è¯•ä¸åŒçš„GPUé…ç½®
            test_configs = [
                TrainingGPUConfig(gpu_count=1, gpu_type='V100', memory_gb=16.0),
                TrainingGPUConfig(gpu_count=2, gpu_type='A100', memory_gb=32.0),
                TrainingGPUConfig(gpu_count=4, gpu_type='T4', memory_gb=8.0),
                TrainingGPUConfig(gpu_count=1, gpu_type='V100', memory_gb=64.0),  # å¯èƒ½ä¸æ»¡è¶³
            ]
            
            for i, config in enumerate(test_configs):
                is_valid = self.gpu_manager.validate_gpu_requirements(config)
                logger.info(f"é…ç½® {i+1}: GPU={config.gpu_count}x{config.gpu_type}, "
                          f"æ˜¾å­˜={config.memory_gb}GB, éªŒè¯ç»“æœ={'âœ…é€šè¿‡' if is_valid else 'âŒä¸æ»¡è¶³'}")
            
            logger.info("âœ… GPUèµ„æºéœ€æ±‚éªŒè¯æµ‹è¯•æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GPUèµ„æºéœ€æ±‚éªŒè¯æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_gpu_resource_allocation(self):
        """æµ‹è¯•GPUèµ„æºåˆ†é…"""
        logger.info("=== æµ‹è¯•GPUèµ„æºåˆ†é… ===")
        
        try:
            # æµ‹è¯•GPUèµ„æºåˆ†é…
            gpu_config = TrainingGPUConfig(
                gpu_count=1,
                gpu_type='V100',
                memory_gb=16.0,
                distributed_training=False
            )
            
            allocated_node = self.gpu_manager.allocate_gpu_resources(gpu_config)
            
            if allocated_node:
                logger.info(f"âœ… GPUèµ„æºåˆ†é…æˆåŠŸ: {allocated_node}")
                
                # æ¸…ç†èµ„æº
                self.gpu_manager.cleanup_gpu_resources(allocated_node, gpu_config.gpu_count)
                logger.info(f"âœ… GPUèµ„æºæ¸…ç†æˆåŠŸ: {allocated_node}")
                return True
            else:
                logger.warning("âš ï¸ GPUèµ„æºåˆ†é…å¤±è´¥ï¼Œå¯èƒ½æ˜¯èµ„æºä¸è¶³")
                return False
                
        except Exception as e:
            logger.error(f"âŒ GPUèµ„æºåˆ†é…æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_tensorflow_gpu_setup(self):
        """æµ‹è¯•TensorFlow GPUè®¾ç½®"""
        logger.info("=== æµ‹è¯•TensorFlow GPUè®¾ç½® ===")
        
        try:
            gpu_config = TrainingGPUConfig(
                gpu_count=1,
                gpu_type='V100',
                memory_gb=16.0,
                distributed_training=False
            )
            
            tf_config = self.tensorflow_gpu.setup_tensorflow_gpu(gpu_config)
            logger.info(f"TensorFlow GPUé…ç½®: {tf_config}")
            
            if tf_config:
                logger.info("âœ… TensorFlow GPUè®¾ç½®æˆåŠŸ")
                return True
            else:
                logger.warning("âš ï¸ TensorFlow GPUè®¾ç½®å¤±è´¥ï¼Œå¯èƒ½æ˜¯TensorFlowæœªå®‰è£…")
                return False
                
        except Exception as e:
            logger.error(f"âŒ TensorFlow GPUè®¾ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_pytorch_gpu_setup(self):
        """æµ‹è¯•PyTorch GPUè®¾ç½®"""
        logger.info("=== æµ‹è¯•PyTorch GPUè®¾ç½® ===")
        
        try:
            gpu_config = TrainingGPUConfig(
                gpu_count=1,
                gpu_type='V100',
                memory_gb=16.0,
                distributed_training=False
            )
            
            pytorch_config = self.pytorch_gpu.setup_pytorch_gpu(gpu_config)
            logger.info(f"PyTorch GPUé…ç½®: {pytorch_config}")
            
            if pytorch_config:
                logger.info("âœ… PyTorch GPUè®¾ç½®æˆåŠŸ")
                return True
            else:
                logger.warning("âš ï¸ PyTorch GPUè®¾ç½®å¤±è´¥ï¼Œå¯èƒ½æ˜¯PyTorchæœªå®‰è£…")
                return False
                
        except Exception as e:
            logger.error(f"âŒ PyTorch GPUè®¾ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_distributed_training_setup(self):
        """æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®"""
        logger.info("=== æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½® ===")
        
        try:
            gpu_config = TrainingGPUConfig(
                gpu_count=2,
                gpu_type='V100',
                memory_gb=32.0,
                distributed_training=True
            )
            
            # æµ‹è¯•åˆ†å¸ƒå¼è®­ç»ƒé…ç½®
            distributed_config = self.gpu_manager.setup_distributed_training(gpu_config)
            logger.info(f"åˆ†å¸ƒå¼è®­ç»ƒé…ç½®: {distributed_config}")
            
            if distributed_config:
                logger.info("âœ… åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®æˆåŠŸ")
                return True
            else:
                logger.warning("âš ï¸ åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®å¤±è´¥ï¼Œå¯èƒ½æ˜¯GPUèµ„æºä¸è¶³")
                return False
                
        except Exception as e:
            logger.error(f"âŒ åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_gpu_monitoring(self):
        """æµ‹è¯•GPUç›‘æ§åŠŸèƒ½"""
        logger.info("=== æµ‹è¯•GPUç›‘æ§åŠŸèƒ½ ===")
        
        try:
            # è·å–GPUç›‘æ§æ•°æ®
            monitoring_data = self.gpu_manager.get_gpu_monitoring_data()
            
            logger.info(f"GPUç›‘æ§æ•°æ®: {monitoring_data}")
            
            # æ£€æŸ¥ç›‘æ§æ•°æ®çš„å…³é”®å­—æ®µ
            required_fields = ['utilization', 'available_nodes', 'total_nodes', 'timestamp']
            missing_fields = [field for field in required_fields if field not in monitoring_data]
            
            if missing_fields:
                logger.warning(f"âš ï¸ ç›‘æ§æ•°æ®ç¼ºå°‘å­—æ®µ: {missing_fields}")
                return False
            else:
                logger.info("âœ… GPUç›‘æ§åŠŸèƒ½æ­£å¸¸")
                return True
                
        except Exception as e:
            logger.error(f"âŒ GPUç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•")
        logger.info("=" * 50)
        
        test_results = []
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        tests = [
            ("GPUç®¡ç†å™¨åˆå§‹åŒ–", self.test_gpu_manager_initialization),
            ("GPUèµ„æºçŠ¶æ€æŸ¥è¯¢", self.test_gpu_resource_status),
            ("GPUèŠ‚ç‚¹å‘ç°", self.test_gpu_node_discovery),
            ("GPUèµ„æºéœ€æ±‚éªŒè¯", self.test_gpu_resource_validation),
            ("GPUèµ„æºåˆ†é…", self.test_gpu_resource_allocation),
            ("TensorFlow GPUè®¾ç½®", self.test_tensorflow_gpu_setup),
            ("PyTorch GPUè®¾ç½®", self.test_pytorch_gpu_setup),
            ("åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®", self.test_distributed_training_setup),
            ("GPUç›‘æ§åŠŸèƒ½", self.test_gpu_monitoring),
        ]
        
        for test_name, test_func in tests:
            try:
                result = test_func()
                test_results.append((test_name, result))
                logger.info(f"{'âœ…' if result else 'âŒ'} {test_name}: {'é€šè¿‡' if result else 'å¤±è´¥'}")
            except Exception as e:
                logger.error(f"âŒ {test_name}: æµ‹è¯•å¼‚å¸¸ - {e}")
                test_results.append((test_name, False))
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        passed_tests = sum(1 for _, result in test_results if result)
        total_tests = len(test_results)
        
        logger.info("=" * 50)
        logger.info(f"ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
        logger.info(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"  é€šè¿‡æµ‹è¯•: {passed_tests}")
        logger.info(f"  å¤±è´¥æµ‹è¯•: {total_tests - passed_tests}")
        logger.info(f"  é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")
        
        if passed_tests == total_tests:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPUèµ„æºç®¡ç†é›†æˆæˆåŠŸ")
        else:
            logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥GPUèµ„æºç®¡ç†å™¨é…ç½®")
        
        return passed_tests == total_tests


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test = GPUResourceIntegrationTest()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    success = test.run_all_tests()
    
    if success:
        logger.info("âœ… GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•å®Œæˆ")
        return 0
    else:
        logger.error("âŒ GPUèµ„æºç®¡ç†é›†æˆæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 