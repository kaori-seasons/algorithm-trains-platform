"""
æµ‹è¯•è´¨é‡è¯„ä¼°å’Œé‡æ–°é¢„å¤„ç†åŠŸèƒ½
"""
import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import tempfile
import os

from quality_assessment.service import QualityAssessmentService, QualityIssue, QualityIssueType
from preprocessing.pipeline import PreprocessingPipeline
from annotation.service import AnnotationService, AnnotationSegment, AnnotationType, SpeedLevel


async def test_quality_assessment():
    """æµ‹è¯•è´¨é‡è¯„ä¼°åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•è´¨é‡è¯„ä¼°åŠŸèƒ½...")
    
    # åˆ›å»ºæ¨¡æ‹ŸæŒ¯åŠ¨æ•°æ®ï¼ˆåŒ…å«è´¨é‡é—®é¢˜ï¼‰
    print("ğŸ“Š åˆ›å»ºåŒ…å«è´¨é‡é—®é¢˜çš„æ¨¡æ‹ŸæŒ¯åŠ¨æ•°æ®...")
    np.random.seed(42)
    n_samples = 5000
    sampling_rate = 1000  # Hz
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    start_time = datetime.now() - timedelta(hours=1)
    timestamps = [start_time + timedelta(seconds=i/sampling_rate) for i in range(n_samples)]
    
    # ç”Ÿæˆæ—¶é—´åºåˆ—
    time = np.arange(n_samples) / sampling_rate
    
    # æ­£å¸¸æŒ¯åŠ¨ä¿¡å·
    normal_vibration = 0.5 * np.sin(2 * np.pi * 50 * time) + 0.1 * np.random.normal(0, 1, n_samples)
    
    # æ·»åŠ è´¨é‡é—®é¢˜
    # 1. æ³¢å½¢ä¸è¿ç»­ï¼ˆè·³è·ƒï¼‰
    jump_start = int(n_samples * 0.3)
    jump_end = int(n_samples * 0.35)
    normal_vibration[jump_start:jump_end] += 3.0  # æ·»åŠ è·³è·ƒ
    
    # 2. å™ªå£°æ±¡æŸ“
    noise_start = int(n_samples * 0.6)
    noise_end = int(n_samples * 0.7)
    normal_vibration[noise_start:noise_end] += 2.0 * np.random.normal(0, 1, noise_end - noise_start)
    
    # 3. æ•°æ®ç¼ºå¤±
    missing_start = int(n_samples * 0.8)
    missing_end = int(n_samples * 0.85)
    normal_vibration[missing_start:missing_end] = np.nan
    
    # 4. å¼‚å¸¸æŒ¯å¹…
    anomaly_start = int(n_samples * 0.4)
    anomaly_end = int(n_samples * 0.45)
    normal_vibration[anomaly_start:anomaly_end] *= 5.0  # æ”¾å¤§æŒ¯å¹…
    
    # åˆ›å»ºæ•°æ®æ¡†
    data = {
        'timestamp': timestamps,
        'x_accel': normal_vibration,
        'y_accel': 0.3 * np.sin(2 * np.pi * 30 * time) + 0.05 * np.random.normal(0, 1, n_samples),
        'z_accel': 0.2 * np.cos(2 * np.pi * 40 * time) + 0.05 * np.random.normal(0, 1, n_samples),
        'speed': np.ones(n_samples) * 1500 + np.random.normal(0, 50, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    with tempfile.TemporaryDirectory() as temp_dir:
        data_path = os.path.join(temp_dir, 'quality_test_data.csv')
        df.to_csv(data_path, index=False)
        
        print(f"âœ… æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ°: {data_path}")
        print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # åˆ›å»ºè´¨é‡è¯„ä¼°æœåŠ¡
        quality_service = QualityAssessmentService()
        
        # é…ç½®è¯„ä¼°å‚æ•°
        assessment_config = {
            'sampling_rate': sampling_rate,
            'jump_threshold': 2.0,
            'min_snr': 15.0,
            'max_missing_ratio': 0.1,
            'frequency_window_size': 500
        }
        
        # æ‰§è¡Œè´¨é‡è¯„ä¼°
        print("\nğŸ” æ‰§è¡Œè´¨é‡è¯„ä¼°...")
        assessment = await quality_service.assess_vibration_quality(df, assessment_config)
        
        print(f"âœ… è´¨é‡è¯„ä¼°å®Œæˆ")
        print(f"   æ€»ä½“è´¨é‡åˆ†æ•°: {assessment.overall_score:.2f}")
        print(f"   è´¨é‡ç­‰çº§: {assessment.quality_level.value}")
        print(f"   å‘ç°é—®é¢˜æ•°é‡: {len(assessment.issues)}")
        
        # æ˜¾ç¤ºå„é€šé“è´¨é‡åˆ†æ•°
        print("\nğŸ“Š å„é€šé“è´¨é‡åˆ†æ•°:")
        for channel, score in assessment.channel_scores.items():
            print(f"   {channel}: {score:.2f}")
        
        # æ˜¾ç¤ºé—®é¢˜è¯¦æƒ…
        print("\nâš ï¸ å‘ç°çš„è´¨é‡é—®é¢˜:")
        for i, issue in enumerate(assessment.issues):
            print(f"   {i+1}. {issue.issue_type.value}: {issue.description}")
            print(f"      ä¸¥é‡ç¨‹åº¦: {issue.severity:.2f}")
            print(f"      å»ºè®®æ“ä½œ: {issue.suggested_action}")
            print(f"      å½±å“é€šé“: {issue.affected_channels}")
        
        print("\nğŸ‰ è´¨é‡è¯„ä¼°åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")


async def test_preprocessing_pipeline():
    """æµ‹è¯•é¢„å¤„ç†ç®¡é“åŠŸèƒ½"""
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•é¢„å¤„ç†ç®¡é“åŠŸèƒ½...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆåŒ…å«è´¨é‡é—®é¢˜ï¼‰
    np.random.seed(42)
    n_samples = 3000
    sampling_rate = 1000
    
    time = np.arange(n_samples) / sampling_rate
    
    # åˆ›å»ºåŒ…å«é—®é¢˜çš„ä¿¡å·
    signal = 0.5 * np.sin(2 * np.pi * 50 * time) + 0.1 * np.random.normal(0, 1, n_samples)
    
    # æ·»åŠ é—®é¢˜
    # æ³¢å½¢è·³è·ƒ
    signal[int(n_samples * 0.3):int(n_samples * 0.35)] += 2.0
    
    # å™ªå£°
    signal[int(n_samples * 0.6):int(n_samples * 0.7)] += 1.5 * np.random.normal(0, 1, 100)
    
    # ç¼ºå¤±æ•°æ®
    signal[int(n_samples * 0.8):int(n_samples * 0.85)] = np.nan
    
    # å¼‚å¸¸æŒ¯å¹…
    signal[int(n_samples * 0.4):int(n_samples * 0.45)] *= 4.0
    
    data = {
        'timestamp': pd.date_range(start=datetime.now(), periods=n_samples, freq='1ms'),
        'x_accel': signal,
        'y_accel': 0.3 * np.sin(2 * np.pi * 30 * time) + 0.05 * np.random.normal(0, 1, n_samples),
        'speed': np.ones(n_samples) * 1500
    }
    
    df = pd.DataFrame(data)
    
    # åˆ›å»ºè´¨é‡è¯„ä¼°æœåŠ¡
    quality_service = QualityAssessmentService()
    
    # æ‰§è¡Œè´¨é‡è¯„ä¼°
    print("ğŸ” æ‰§è¡Œè´¨é‡è¯„ä¼°...")
    assessment = await quality_service.assess_vibration_quality(df, {'sampling_rate': sampling_rate})
    
    print(f"   å‘ç°é—®é¢˜æ•°é‡: {len(assessment.issues)}")
    
    # åˆ›å»ºé¢„å¤„ç†ç®¡é“
    preprocessing_pipeline = PreprocessingPipeline()
    
    # é…ç½®é¢„å¤„ç†å‚æ•°
    preprocessing_config = {
        'sampling_rate': sampling_rate,
        'discontinuity_cutoff_freq': 100,
        'noise_low_cutoff': 10,
        'noise_high_cutoff': 500,
        'frequency_correction_window': 100
    }
    
    # æ‰§è¡Œé¢„å¤„ç†
    print("\nğŸ”„ æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
    result = await preprocessing_pipeline.process_data(df, assessment.issues, preprocessing_config)
    
    print(f"âœ… é¢„å¤„ç†å®Œæˆ")
    print(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {result.original_data.shape}")
    print(f"   å¤„ç†åæ•°æ®å½¢çŠ¶: {result.processed_data.shape}")
    print(f"   å¤„ç†æ­¥éª¤æ•°é‡: {len(result.steps)}")
    print(f"   å¤„ç†è€—æ—¶: {result.processing_time:.2f}ç§’")
    
    # æ˜¾ç¤ºå¤„ç†æ­¥éª¤
    print("\nğŸ“‹ å¤„ç†æ­¥éª¤:")
    for i, step in enumerate(result.steps):
        print(f"   {i+1}. {step.step_type.value}: {step.description}")
        print(f"      åº”ç”¨é€šé“: {step.applied_channels}")
        print(f"      å‚æ•°: {step.parameters}")
    
    # æ˜¾ç¤ºè´¨é‡æ”¹å–„
    print("\nğŸ“ˆ è´¨é‡æ”¹å–„æƒ…å†µ:")
    for channel, improvement in result.quality_improvement.items():
        print(f"   {channel}: {improvement:.2f}%")
    
    print("\nğŸ‰ é¢„å¤„ç†ç®¡é“åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")


async def test_annotation_service():
    """æµ‹è¯•æ ‡æ³¨æœåŠ¡åŠŸèƒ½"""
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•æ ‡æ³¨æœåŠ¡åŠŸèƒ½...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 2000
    sampling_rate = 1000
    
    time = np.arange(n_samples) / sampling_rate
    signal = 0.5 * np.sin(2 * np.pi * 50 * time) + 0.1 * np.random.normal(0, 1, n_samples)
    
    data = {
        'timestamp': pd.date_range(start=datetime.now(), periods=n_samples, freq='1ms'),
        'x_accel': signal,
        'y_accel': 0.3 * np.sin(2 * np.pi * 30 * time) + 0.05 * np.random.normal(0, 1, n_samples),
        'speed': np.ones(n_samples) * 1500
    }
    
    df = pd.DataFrame(data)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    with tempfile.TemporaryDirectory() as temp_dir:
        data_path = os.path.join(temp_dir, 'annotation_test_data.csv')
        df.to_csv(data_path, index=False)
        
        # åˆ›å»ºæ ‡æ³¨æœåŠ¡
        annotation_service = AnnotationService()
        
        # åˆ›å»ºæ ‡æ³¨ä»»åŠ¡
        print("ğŸ“ åˆ›å»ºæ ‡æ³¨ä»»åŠ¡...")
        task_config = {
            'assigned_user': 'test_user',
            'description': 'æµ‹è¯•æ ‡æ³¨ä»»åŠ¡'
        }
        
        task_id = await annotation_service.create_annotation_task(data_path, task_config)
        print(f"   ä»»åŠ¡ID: {task_id}")
        
        # æ·»åŠ è½¬é€Ÿæ ‡æ³¨
        print("\nğŸ·ï¸ æ·»åŠ è½¬é€Ÿæ ‡æ³¨...")
        speed_segment = AnnotationSegment(
            start_time=datetime.now(),
            end_time=datetime.now() + timedelta(minutes=10),
            annotation_type=AnnotationType.SPEED_RANGE,
            label=SpeedLevel.MEDIUM_SPEED.value,
            confidence=0.9,
            metadata={'speed_value': 1500}
        )
        
        success = await annotation_service.add_annotation_segment(task_id, speed_segment)
        print(f"   è½¬é€Ÿæ ‡æ³¨æ·»åŠ : {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # æ·»åŠ è´¨é‡æ ‡æ³¨
        print("\nğŸ·ï¸ æ·»åŠ è´¨é‡æ ‡æ³¨...")
        quality_segment = AnnotationSegment(
            start_time=datetime.now() + timedelta(minutes=5),
            end_time=datetime.now() + timedelta(minutes=8),
            annotation_type=AnnotationType.QUALITY_MARK,
            label='good',
            confidence=0.8,
            metadata={'quality_score': 85}
        )
        
        success = await annotation_service.add_annotation_segment(task_id, quality_segment)
        print(f"   è´¨é‡æ ‡æ³¨æ·»åŠ : {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # è·å–æ ‡æ³¨æ•°æ®
        print("\nğŸ“Š è·å–æ ‡æ³¨æ•°æ®...")
        annotation_data = await annotation_service.get_annotation_data(task_id)
        print(f"   æ ‡æ³¨æ®µæ•°é‡: {len(annotation_data['segments'])}")
        print(f"   æ—¶é—´åºåˆ—é€šé“: {list(annotation_data['time_series_data'].keys())}")
        
        # è·å–è½¬é€Ÿæ ‡æ³¨
        speed_annotations = await annotation_service.get_speed_annotations(task_id)
        print(f"   è½¬é€Ÿæ ‡æ³¨æ•°é‡: {len(speed_annotations)}")
        
        # è·å–è´¨é‡æ ‡æ³¨
        quality_annotations = await annotation_service.get_quality_annotations(task_id)
        print(f"   è´¨é‡æ ‡æ³¨æ•°é‡: {len(quality_annotations)}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        statistics = await annotation_service.get_annotation_statistics(task_id)
        print(f"\nğŸ“ˆ æ ‡æ³¨ç»Ÿè®¡:")
        print(f"   æ€»æ ‡æ³¨æ®µ: {statistics['total_segments']}")
        print(f"   ç±»å‹åˆ†å¸ƒ: {statistics['type_distribution']}")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {statistics['label_distribution']}")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {statistics['average_confidence']:.2f}")
        
        # å¯¼å‡ºæ ‡æ³¨ç»“æœ
        print("\nğŸ“¤ å¯¼å‡ºæ ‡æ³¨ç»“æœ...")
        export_data = await annotation_service.export_annotations(task_id, 'json')
        print(f"   å¯¼å‡ºæ•°æ®é•¿åº¦: {len(export_data)} å­—ç¬¦")
        
        print("\nğŸ‰ æ ‡æ³¨æœåŠ¡åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")


async def test_integrated_workflow():
    """æµ‹è¯•é›†æˆå·¥ä½œæµ"""
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•é›†æˆå·¥ä½œæµ...")
    
    # 1. åˆ›å»ºåŒ…å«è´¨é‡é—®é¢˜çš„æ•°æ®
    print("ğŸ“Š æ­¥éª¤1: åˆ›å»ºæµ‹è¯•æ•°æ®...")
    np.random.seed(42)
    n_samples = 4000
    sampling_rate = 1000
    
    time = np.arange(n_samples) / sampling_rate
    signal = 0.5 * np.sin(2 * np.pi * 50 * time) + 0.1 * np.random.normal(0, 1, n_samples)
    
    # æ·»åŠ è´¨é‡é—®é¢˜
    signal[int(n_samples * 0.3):int(n_samples * 0.35)] += 2.0  # è·³è·ƒ
    signal[int(n_samples * 0.6):int(n_samples * 0.7)] += 1.5 * np.random.normal(0, 1, 100)  # å™ªå£°
    signal[int(n_samples * 0.8):int(n_samples * 0.85)] = np.nan  # ç¼ºå¤±
    
    data = {
        'timestamp': pd.date_range(start=datetime.now(), periods=n_samples, freq='1ms'),
        'x_accel': signal,
        'y_accel': 0.3 * np.sin(2 * np.pi * 30 * time) + 0.05 * np.random.normal(0, 1, n_samples),
        'speed': np.ones(n_samples) * 1500
    }
    
    df = pd.DataFrame(data)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        data_path = os.path.join(temp_dir, 'workflow_test_data.csv')
        df.to_csv(data_path, index=False)
        
        # 2. è´¨é‡è¯„ä¼°
        print("\nğŸ” æ­¥éª¤2: è´¨é‡è¯„ä¼°...")
        quality_service = QualityAssessmentService()
        assessment = await quality_service.assess_vibration_quality(df, {'sampling_rate': sampling_rate})
        
        print(f"   è´¨é‡åˆ†æ•°: {assessment.overall_score:.2f}")
        print(f"   é—®é¢˜æ•°é‡: {len(assessment.issues)}")
        
        # 3. æ•°æ®é¢„å¤„ç†
        print("\nğŸ”„ æ­¥éª¤3: æ•°æ®é¢„å¤„ç†...")
        preprocessing_pipeline = PreprocessingPipeline()
        result = await preprocessing_pipeline.process_data(df, assessment.issues, {'sampling_rate': sampling_rate})
        
        print(f"   å¤„ç†æ­¥éª¤: {len(result.steps)}")
        print(f"   è´¨é‡æ”¹å–„: {np.mean(list(result.quality_improvement.values())):.2f}%")
        
        # 4. åˆ›å»ºæ ‡æ³¨ä»»åŠ¡
        print("\nğŸ“ æ­¥éª¤4: åˆ›å»ºæ ‡æ³¨ä»»åŠ¡...")
        annotation_service = AnnotationService()
        task_id = await annotation_service.create_annotation_task(data_path, {})
        
        # 5. æ·»åŠ æ ‡æ³¨
        print("\nğŸ·ï¸ æ­¥éª¤5: æ·»åŠ æ ‡æ³¨...")
        segment = AnnotationSegment(
            start_time=datetime.now(),
            end_time=datetime.now() + timedelta(minutes=5),
            annotation_type=AnnotationType.SPEED_RANGE,
            label=SpeedLevel.MEDIUM_SPEED.value,
            confidence=0.9
        )
        
        await annotation_service.add_annotation_segment(task_id, segment)
        
        # 6. è·å–ç»“æœ
        print("\nğŸ“Š æ­¥éª¤6: è·å–ç»“æœ...")
        annotation_data = await annotation_service.get_annotation_data(task_id)
        statistics = await annotation_service.get_annotation_statistics(task_id)
        
        print(f"   æ ‡æ³¨æ®µ: {statistics['total_segments']}")
        print(f"   æ—¶é—´åºåˆ—é€šé“: {len(annotation_data['time_series_data'])}")
        
        print("\nğŸ‰ é›†æˆå·¥ä½œæµæµ‹è¯•å®Œæˆï¼")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è´¨é‡è¯„ä¼°ç³»ç»Ÿæµ‹è¯•...")
    
    try:
        await test_quality_assessment()
        await test_preprocessing_pipeline()
        await test_annotation_service()
        await test_integrated_workflow()
        
        print("\nâœ… æ‰€æœ‰è´¨é‡è¯„ä¼°åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 