# Epochè®­ç»ƒåŠŸèƒ½ä½¿ç”¨æŒ‡å—

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

æœ¬ç³»ç»Ÿç°åœ¨æ”¯æŒå®Œæ•´çš„TensorFlow/PyTorch epochè½®æ¬¡è®­ç»ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- âœ… **å®Œæ•´epochè®­ç»ƒæµç¨‹**
- âœ… **å®æ—¶è¿›åº¦ç›‘æ§**
- âœ… **æ—©åœæœºåˆ¶**
- âœ… **å­¦ä¹ ç‡è°ƒåº¦**
- âœ… **è®­ç»ƒæ§åˆ¶ï¼ˆæš‚åœ/æ¢å¤ï¼‰**
- âœ… **å¤šGPUæ”¯æŒ**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨Epochè®­ç»ƒ

```python
import requests
import json

# é…ç½®è®­ç»ƒå‚æ•°
config = {
    "name": "æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
    "algorithm_type": "deep_learning",
    "model_type": "mlp",
    "epochs": 100,
    "batch_size": 32,
    "learning_rate": 0.001,
    "hidden_units": [128, 64, 32],
    "dropout_rate": 0.2,
    "early_stopping_patience": 10,
    "learning_rate_scheduler": "step",
    "feature_columns": ["feature1", "feature2", "feature3"],
    "target_column": "target",
    "output_path": "/models/deep_learning_model"
}

# å¯åŠ¨è®­ç»ƒ
response = requests.post(
    "http://localhost:8000/api/v1/epoch-training/start",
    json=config,
    headers={"Authorization": "Bearer your_token"}
)

task_id = response.json()["task_id"]
print(f"è®­ç»ƒä»»åŠ¡ID: {task_id}")
```

### 2. ç›‘æ§è®­ç»ƒè¿›åº¦

```python
# è·å–è®­ç»ƒè¿›åº¦
response = requests.get(f"http://localhost:8000/api/v1/epoch-training/progress/{task_id}")
progress = response.json()["progress"]

print(f"å½“å‰epoch: {progress['current_epoch']}")
print(f"è®­ç»ƒçŠ¶æ€: {progress['training_state']}")
print(f"æœ€æ–°æŒ‡æ ‡: {progress['latest_metrics']}")
```

### 3. æµå¼ç›‘æ§ï¼ˆSSEï¼‰

```python
import sseclient

# æµå¼è·å–è®­ç»ƒè¿›åº¦
response = requests.get(
    f"http://localhost:8000/api/v1/epoch-training/stream-progress/{task_id}",
    stream=True
)

client = sseclient.SSEClient(response)
for event in client.events():
    data = json.loads(event.data)
    if data["type"] == "progress":
        epoch = data["progress"]["current_epoch"]
        metrics = data["progress"]["latest_metrics"]
        print(f"Epoch {epoch}: Loss={metrics['train_loss']:.4f}, Acc={metrics['train_accuracy']:.4f}")
    elif data["type"] == "complete":
        print("è®­ç»ƒå®Œæˆ!")
        break
```

### 4. è®­ç»ƒæ§åˆ¶

```python
# æš‚åœè®­ç»ƒ
requests.post(f"http://localhost:8000/api/v1/epoch-training/pause/{task_id}")

# æ¢å¤è®­ç»ƒ
requests.post(f"http://localhost:8000/api/v1/epoch-training/resume/{task_id}")
```

## ğŸ“Š APIæ¥å£è¯¦è§£

### å¯åŠ¨è®­ç»ƒ

**POST** `/api/v1/epoch-training/start`

```json
{
  "name": "æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
  "algorithm_type": "deep_learning",
  "model_type": "mlp",
  "epochs": 100,
  "batch_size": 32,
  "learning_rate": 0.001,
  "hidden_units": [128, 64, 32],
  "dropout_rate": 0.2,
  "early_stopping_patience": 10,
  "learning_rate_scheduler": "step",
  "feature_columns": ["feature1", "feature2", "feature3"],
  "target_column": "target",
  "output_path": "/models/deep_learning_model"
}
```

**å“åº”:**
```json
{
  "success": true,
  "task_id": "epoch_training_20240101_120000",
  "message": "Epochè®­ç»ƒå·²å¯åŠ¨",
  "config": {...}
}
```

### è·å–è®­ç»ƒè¿›åº¦

**GET** `/api/v1/epoch-training/progress/{task_id}`

**å“åº”:**
```json
{
  "success": true,
  "task_id": "epoch_training_20240101_120000",
  "progress": {
    "current_epoch": 25,
    "total_epochs": 100,
    "training_state": "running",
    "latest_metrics": {
      "epoch": 25,
      "train_loss": 0.1234,
      "train_accuracy": 0.9234,
      "val_loss": 0.1456,
      "val_accuracy": 0.9123,
      "learning_rate": 0.001,
      "time_per_epoch": 45.2
    },
    "best_metrics": {
      "loss": 0.1234,
      "accuracy": 0.9234
    }
  }
}
```

### è·å–è®­ç»ƒå†å²

**GET** `/api/v1/epoch-training/history/{task_id}`

**å“åº”:**
```json
{
  "success": true,
  "task_id": "epoch_training_20240101_120000",
  "history": [
    {
      "epoch": 1,
      "train_loss": 0.2345,
      "train_accuracy": 0.8567,
      "val_loss": 0.1987,
      "val_accuracy": 0.8723,
      "learning_rate": 0.001,
      "time_per_epoch": 42.1
    },
    // ... æ›´å¤šepochè®°å½•
  ]
}
```

## ğŸ”§ é…ç½®å‚æ•°è¯¦è§£

### æ¨¡å‹é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `model_type` | string | "mlp" | æ¨¡å‹ç±»å‹ï¼ˆmlp, cnn, lstm, gruï¼‰ |
| `hidden_units` | list | [64, 32] | éšè—å±‚å•å…ƒæ•° |
| `dropout_rate` | float | 0.2 | Dropoutæ¯”ç‡ |

### è®­ç»ƒé…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `epochs` | int | 100 | è®­ç»ƒè½®æ•° |
| `batch_size` | int | 32 | æ‰¹æ¬¡å¤§å° |
| `learning_rate` | float | 0.001 | å­¦ä¹ ç‡ |

### æ—©åœé…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `early_stopping_patience` | int | 10 | æ—©åœè€å¿ƒå€¼ |
| `min_delta` | float | 0.001 | æœ€å°æ”¹å–„é˜ˆå€¼ |

### å­¦ä¹ ç‡è°ƒåº¦é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `learning_rate_scheduler` | string | "step" | è°ƒåº¦å™¨ç±»å‹ |
| `step_size` | int | 30 | æ­¥è¿›é—´éš”ï¼ˆstepè°ƒåº¦å™¨ï¼‰ |
| `gamma` | float | 0.1 | è¡°å‡å› å­ |

## ğŸ“ˆ æ”¯æŒçš„è°ƒåº¦å™¨ç±»å‹

### 1. æ­¥è¿›è°ƒåº¦å™¨ (step)
```python
# æ¯30ä¸ªepoché™ä½å­¦ä¹ ç‡
config = {
    "learning_rate_scheduler": "step",
    "step_size": 30,
    "gamma": 0.1
}
```

### 2. å¹³å°è°ƒåº¦å™¨ (plateau)
```python
# å½“éªŒè¯æŸå¤±ä¸å†æ”¹å–„æ—¶é™ä½å­¦ä¹ ç‡
config = {
    "learning_rate_scheduler": "plateau",
    "patience": 5,
    "factor": 0.5
}
```

### 3. ä½™å¼¦é€€ç« (cosine)
```python
# ä½¿ç”¨ä½™å¼¦å‡½æ•°å¹³æ»‘é™ä½å­¦ä¹ ç‡
config = {
    "learning_rate_scheduler": "cosine",
    "T_max": 100,
    "eta_min": 0.0001
}
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: åŸºç¡€MLPè®­ç»ƒ

```python
config = {
    "name": "åŸºç¡€MLPè®­ç»ƒ",
    "algorithm_type": "deep_learning",
    "model_type": "mlp",
    "epochs": 50,
    "batch_size": 64,
    "learning_rate": 0.001,
    "hidden_units": [128, 64],
    "dropout_rate": 0.3,
    "early_stopping_patience": 5,
    "learning_rate_scheduler": "step",
    "feature_columns": ["feature1", "feature2", "feature3"],
    "target_column": "target",
    "output_path": "/models/mlp_model"
}
```

### ç¤ºä¾‹2: å¤æ‚ç½‘ç»œè®­ç»ƒ

```python
config = {
    "name": "å¤æ‚ç½‘ç»œè®­ç»ƒ",
    "algorithm_type": "deep_learning",
    "model_type": "mlp",
    "epochs": 200,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "hidden_units": [256, 128, 64, 32],
    "dropout_rate": 0.5,
    "early_stopping_patience": 15,
    "learning_rate_scheduler": "plateau",
    "feature_columns": ["feature1", "feature2", "feature3", "feature4"],
    "target_column": "target",
    "output_path": "/models/complex_model"
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **TensorFlow/PyTorchæœªå®‰è£…**
   ```
   è§£å†³æ–¹æ¡ˆ: pip install tensorflow torch
   ```

2. **GPUå†…å­˜ä¸è¶³**
   ```
   è§£å†³æ–¹æ¡ˆ: å‡å°‘batch_sizeæˆ–ä½¿ç”¨CPUè®­ç»ƒ
   ```

3. **è®­ç»ƒé€Ÿåº¦æ…¢**
   ```
   è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥GPUä½¿ç”¨ç‡ï¼Œè°ƒæ•´batch_size
   ```

4. **æ—©åœè¿‡æ—©è§¦å‘**
   ```
   è§£å†³æ–¹æ¡ˆ: å¢åŠ patienceå€¼æˆ–è°ƒæ•´min_delta
   ```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨GPUè®­ç»ƒ**
   ```python
   # æ£€æŸ¥GPUå¯ç”¨æ€§
   import tensorflow as tf
   print("GPUæ•°é‡:", len(tf.config.list_physical_devices('GPU')))
   ```

2. **è°ƒæ•´æ‰¹æ¬¡å¤§å°**
   ```python
   # æ ¹æ®GPUå†…å­˜è°ƒæ•´
   config["batch_size"] = 64  # æˆ–æ›´å¤§
   ```

3. **ä½¿ç”¨æ··åˆç²¾åº¦**
   ```python
   # åœ¨TensorFlowä¸­å¯ç”¨æ··åˆç²¾åº¦
   policy = tf.keras.mixed_precision.Policy('mixed_float16')
   tf.keras.mixed_precision.set_global_policy(policy)
   ```

## ğŸ“š æ›´å¤šèµ„æº

- [TensorFlowå®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/)
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/)
- [æ·±åº¦å­¦ä¹ æœ€ä½³å®è·µ](https://github.com/keras-team/keras/blob/master/keras/guides/)
- [é¡¹ç›®GitHubä»“åº“](https://github.com/your-repo/train-storge-workflow)

è¿™ä¸ªepochè®­ç»ƒåŠŸèƒ½ä¸ºç³»ç»Ÿæä¾›äº†å®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæ”¯æŒï¼ŒåŒ…æ‹¬å®æ—¶ç›‘æ§ã€è‡ªåŠ¨ä¼˜åŒ–å’Œçµæ´»çš„é…ç½®é€‰é¡¹ã€‚ 