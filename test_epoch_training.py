"""
Epochè®­ç»ƒåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•TensorFlow/PyTorch epochè½®æ¬¡è®­ç»ƒåŠŸèƒ½
"""
import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from backend.algorithm_engine.epoch_trainers import EpochDeepLearningTrainer, epoch_training_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_epoch_training():
    """æµ‹è¯•epochè®­ç»ƒåŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•Epochè®­ç»ƒåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = EpochDeepLearningTrainer()
        
        # é…ç½®è®­ç»ƒå‚æ•°
        config = {
            "name": "æµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹",
            "algorithm_type": "deep_learning",
            "model_type": "mlp",
            "epochs": 10,  # æµ‹è¯•ç”¨è¾ƒå°‘çš„epoch
            "batch_size": 32,
            "learning_rate": 0.001,
            "hidden_units": [64, 32],
            "dropout_rate": 0.2,
            "early_stopping_patience": 5,
            "learning_rate_scheduler": "step",
            "feature_columns": ["feature1", "feature2", "feature3"],
            "target_column": "target",
            "output_path": "./test_models"
        }
        
        # æ¨¡æ‹Ÿæ•°æ®
        data = {
            "train_data": "æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®",
            "train_labels": "æ¨¡æ‹Ÿè®­ç»ƒæ ‡ç­¾",
            "val_data": "æ¨¡æ‹ŸéªŒè¯æ•°æ®",
            "val_labels": "æ¨¡æ‹ŸéªŒè¯æ ‡ç­¾"
        }
        
        print(f"ğŸ“‹ è®­ç»ƒé…ç½®: {config}")
        print(f"ğŸ“Š æ•°æ®é…ç½®: {list(data.keys())}")
        
        # å¯åŠ¨è®­ç»ƒ
        print("ğŸš€ å¯åŠ¨Epochè®­ç»ƒ...")
        result = await trainer.train_with_epochs(config, data, task_id="test_epoch_training")
        
        print(f"âœ… è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ˆ è®­ç»ƒç»“æœ: {result}")
        
        # æ£€æŸ¥è®­ç»ƒå†å²
        if trainer.epoch_history:
            print(f"ğŸ“Š è®­ç»ƒå†å²è®°å½•æ•°: {len(trainer.epoch_history)}")
            print(f"ğŸ† æœ€ä½³epoch: {trainer.early_stopping.get_best_epoch()}")
            
            # æ˜¾ç¤ºæœ€åå‡ ä¸ªepochçš„æŒ‡æ ‡
            print("\nğŸ“ˆ æœ€å5ä¸ªepochçš„æŒ‡æ ‡:")
            for metrics in trainer.epoch_history[-5:]:
                print(f"  Epoch {metrics.epoch}: "
                      f"Train Loss={metrics.train_loss:.4f}, "
                      f"Train Acc={metrics.train_accuracy:.4f}, "
                      f"Val Loss={metrics.val_loss:.4f}, "
                      f"Val Acc={metrics.val_accuracy:.4f}")
        
        return result
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


async def test_training_progress():
    """æµ‹è¯•è®­ç»ƒè¿›åº¦ç›‘æ§"""
    print("\nğŸ§ª æµ‹è¯•è®­ç»ƒè¿›åº¦ç›‘æ§...")
    
    try:
        # è·å–è®­ç»ƒè¿›åº¦
        progress = epoch_training_manager.get_training_progress()
        print(f"ğŸ“Š å½“å‰è®­ç»ƒè¿›åº¦: {progress}")
        
        # æµ‹è¯•æš‚åœå’Œæ¢å¤
        print("â¸ï¸  æµ‹è¯•æš‚åœè®­ç»ƒ...")
        epoch_training_manager.pause_training()
        
        progress = epoch_training_manager.get_training_progress()
        print(f"ğŸ“Š æš‚åœåè¿›åº¦: {progress}")
        
        print("â–¶ï¸  æµ‹è¯•æ¢å¤è®­ç»ƒ...")
        epoch_training_manager.resume_training()
        
        progress = epoch_training_manager.get_training_progress()
        print(f"ğŸ“Š æ¢å¤åè¿›åº¦: {progress}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¿›åº¦ç›‘æ§æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åˆ›å»ºåŠŸèƒ½...")
    
    try:
        trainer = EpochDeepLearningTrainer()
        
        # æµ‹è¯•TensorFlowæ¨¡å‹åˆ›å»º
        print("ğŸ”§ æµ‹è¯•TensorFlowæ¨¡å‹åˆ›å»º...")
        config = {
            "model_type": "mlp",
            "hidden_units": [64, 32],
            "dropout_rate": 0.2,
            "learning_rate": 0.001,
            "feature_columns": ["feature1", "feature2", "feature3"]
        }
        
        trainer._initialize_training(config, {})
        
        if trainer.tf_model:
            print("âœ… TensorFlowæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        elif trainer.pytorch_model:
            print("âœ… PyTorchæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        else:
            print("âš ï¸  æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œå¯èƒ½éœ€è¦å®‰è£…TensorFlowæˆ–PyTorch")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_early_stopping():
    """æµ‹è¯•æ—©åœæœºåˆ¶"""
    print("\nğŸ§ª æµ‹è¯•æ—©åœæœºåˆ¶...")
    
    try:
        from backend.algorithm_engine.epoch_trainers import EarlyStopping
        
        early_stopping = EarlyStopping(patience=3, min_delta=0.001)
        
        # æ¨¡æ‹ŸéªŒè¯æŸå¤±
        val_losses = [0.5, 0.4, 0.35, 0.34, 0.33, 0.32, 0.31, 0.30]
        
        for epoch, loss in enumerate(val_losses):
            should_stop = early_stopping.should_stop(loss, epoch)
            print(f"  Epoch {epoch}: Loss={loss:.3f}, Should Stop={should_stop}")
            
            if should_stop:
                print(f"ğŸ›‘ æ—©åœè§¦å‘äºç¬¬{epoch}è½®")
                break
        
        best_epoch = early_stopping.get_best_epoch()
        print(f"ğŸ† æœ€ä½³epoch: {best_epoch}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ—©åœæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_learning_rate_scheduler():
    """æµ‹è¯•å­¦ä¹ ç‡è°ƒåº¦å™¨"""
    print("\nğŸ§ª æµ‹è¯•å­¦ä¹ ç‡è°ƒåº¦å™¨...")
    
    try:
        from backend.algorithm_engine.epoch_trainers import LearningRateScheduler
        
        # æµ‹è¯•æ­¥è¿›è°ƒåº¦å™¨
        scheduler = LearningRateScheduler(initial_lr=0.001, scheduler_type='step')
        
        print("ğŸ“ˆ å­¦ä¹ ç‡å˜åŒ–:")
        for epoch in range(10):
            lr = scheduler.get_current_lr()
            scheduler.step(epoch, {'val_loss': 0.5})
            print(f"  Epoch {epoch}: LR={lr:.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å­¦ä¹ ç‡è°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Epochè®­ç»ƒåŠŸèƒ½æµ‹è¯•...")
    
    try:
        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        await test_model_creation()
        
        # æµ‹è¯•æ—©åœæœºåˆ¶
        await test_early_stopping()
        
        # æµ‹è¯•å­¦ä¹ ç‡è°ƒåº¦å™¨
        await test_learning_rate_scheduler()
        
        # æµ‹è¯•è®­ç»ƒè¿›åº¦ç›‘æ§
        await test_training_progress()
        
        # æµ‹è¯•å®Œæ•´è®­ç»ƒæµç¨‹
        await test_epoch_training()
        
        print("\nâœ… æ‰€æœ‰Epochè®­ç»ƒæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 