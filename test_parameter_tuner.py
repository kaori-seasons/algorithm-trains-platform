#!/usr/bin/env python3
"""
å‚æ•°è°ƒä¼˜æ¨¡å—æµ‹è¯•è„šæœ¬
"""
import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from backend.algorithm_engine.parameter_tuner import InteractiveParameterTuner
from backend.algorithm_engine.model_manager import ModelVersionManager
from backend.algorithm_engine.inference_service import RealTimeInferenceService
from backend.algorithm_engine.models import AlgorithmType

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_parameter_tuner():
    """æµ‹è¯•å‚æ•°è°ƒä¼˜å™¨"""
    print("ğŸ§ª æµ‹è¯•å‚æ•°è°ƒä¼˜å™¨...")
    
    try:
        # åˆ›å»ºå‚æ•°è°ƒä¼˜å™¨
        tuner = InteractiveParameterTuner()
        
        # æµ‹è¯•åˆ›å»ºå‚æ•°ç•Œé¢
        algorithm_config = {
            'algorithm_type': 'status_recognition',
            'parameters': {
                'threshold': 0.5,
                'n_estimators': 100
            }
        }
        
        interface = await tuner.create_parameter_interface(algorithm_config)
        print(f"âœ… å‚æ•°ç•Œé¢åˆ›å»ºæˆåŠŸ: {interface['interface']['algorithm_type']}")
        
        # æµ‹è¯•å‚æ•°æ›´æ–°
        new_params = {'threshold': 0.7, 'n_estimators': 150}
        result = await tuner.update_parameters(new_params)
        print(f"âœ… å‚æ•°æ›´æ–°æˆåŠŸ: {result['status']}")
        
        # æµ‹è¯•å‚æ•°é€‰æ‹©
        selection_data = {
            'type': 'threshold',
            'value': 0.8
        }
        selection_result = await tuner.apply_parameter_selection(selection_data)
        print(f"âœ… å‚æ•°é€‰æ‹©åº”ç”¨æˆåŠŸ: {selection_result['status']}")
        
        # æµ‹è¯•å¯¼å‡ºæœ€ä¼˜å‚æ•°
        optimal_params = await tuner.export_optimal_parameters()
        print(f"âœ… æœ€ä¼˜å‚æ•°å¯¼å‡ºæˆåŠŸ: {optimal_params['status']}")
        
        print("ğŸ‰ å‚æ•°è°ƒä¼˜å™¨æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ å‚æ•°è°ƒä¼˜å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_model_manager():
    """æµ‹è¯•æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨...")
    
    try:
        # åˆ›å»ºæ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨
        manager = ModelVersionManager()
        
        # æµ‹è¯•åˆ—å‡ºç‰ˆæœ¬
        versions = await manager.list_versions()
        print(f"âœ… ç‰ˆæœ¬åˆ—è¡¨è·å–æˆåŠŸ: {len(versions)} ä¸ªç‰ˆæœ¬")
        
        # æµ‹è¯•è·å–ç‰ˆæœ¬è¯¦æƒ…
        if versions:
            version_id = versions[0]['version_id']
            details = await manager.get_version_details(version_id)
            print(f"âœ… ç‰ˆæœ¬è¯¦æƒ…è·å–æˆåŠŸ: {details['status']}")
        
        print("ğŸ‰ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_inference_service():
    """æµ‹è¯•æ¨ç†æœåŠ¡"""
    print("ğŸ§ª æµ‹è¯•æ¨ç†æœåŠ¡...")
    
    try:
        # åˆ›å»ºæ¨ç†æœåŠ¡
        service = RealTimeInferenceService()
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await service.health_check()
        print(f"âœ… å¥åº·æ£€æŸ¥æˆåŠŸ: {health['status']}")
        
        # æµ‹è¯•æœåŠ¡ç»Ÿè®¡
        stats = service.get_service_stats()
        print(f"âœ… æœåŠ¡ç»Ÿè®¡è·å–æˆåŠŸ: ç¼“å­˜å¤§å°={stats['cache_stats']['size']}")
        
        print("ğŸ‰ æ¨ç†æœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨ç†æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å‚æ•°è°ƒä¼˜ç›¸å…³æ¨¡å—...")
    
    results = []
    
    # æµ‹è¯•å‚æ•°è°ƒä¼˜å™¨
    results.append(await test_parameter_tuner())
    
    # æµ‹è¯•æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å™¨
    results.append(await test_model_manager())
    
    # æµ‹è¯•æ¨ç†æœåŠ¡
    results.append(await test_inference_service())
    
    # æ€»ç»“
    success_count = sum(results)
    total_count = len(results)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   æˆåŠŸ: {success_count}/{total_count}")
    print(f"   å¤±è´¥: {total_count - success_count}/{total_count}")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    asyncio.run(main()) 